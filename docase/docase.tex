\documentclass{sigplanconf}

%include polycode.fmt

\usepackage{amsmath}
\usepackage{mathpartir}
\usepackage{multicol}
\usepackage{color}
\usepackage{verbatim}

\begin{document}
% --------------------------------------------------------------------------------------------------
%format ^ = " "
%format ^^ = "\;"
%format instancesem_ = "\mathbf{instance_{sem}}$ \ $"
%format docase_ = "\mathbf{docase}"
%format mcase_ = "\mathbf{mcase}"
%format pcase_ = "\mathbf{pcase}"
%format inf_ = "\infty"
%format forall_ = "\forall"
%format bot_ = "\bot"
%format sp_  = "$ \ $"
%format smp_  = "$\,$"
%format ssp_  = "$ \qquad \quad $"
%format lsp_  = "\\[-17pt]"
%format neq_ = "\neq"
%format morelse_ = "\oplus"
%format mplus_ = "\oplus"
%format pi1_ = "\pi 1"
%format pin_ = "\pi n"
%format mzip_ = "\otimes"
%format pfail_ = "\bullet"
%format star_ = "\star"
%format diamond_ = "\diamond"
%format sub(a) = "_{" a "}"
%format sup(a) = "^{" a "}"
%format sm(a) = "\mathopen{\llbracket} " a "\mathclose{\rrbracket} "
%format tsm(a) = "\mathopen{\langle} " a "\mathclose{\rangle} "

\newcommand{\ident}[1]{{\normalfont\sffamily #1}}
\newcommand{\code}[1]{{\normalfont\ttfamily #1}}
\newcommand{\mzip}[0]{\otimes}
\newcommand{\morelse}[0]{\oplus}
\newcommand{\mzero}[0]{\Varid{mzero}}
\newcommand{\munit}[0]{\Varid{unit}}
\newcommand{\map}[0]{\Varid{map}}
\newcommand{\malias}[0]{\Varid{malias}}
\newcommand{\mcojoin}[0]{\Varid{cojoin}}
\newcommand{\mplus}[0]{\oplus}
\newcommand{\fsharp}[0]{F$^\#$}
\newcommand{\todo}[1]{\textcolor{red}{[TODO] #1}}

\conferenceinfo{Haskell'11,} {September 22, 2011, Tokyo, Japan.}
\CopyrightYear{2011}
\copyrightdata{978-1-4503-0860-1/11/09} 

%\titlebanner{Unpublished draft}        % These are ignored unless
%\preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Extending Monads with Pattern Matching}

\authorinfo{Tomas Petricek \and Alan Mycroft}
           {University of Cambridge}
           {\{tomas.petricek, am\}@@cl.cam.ac.uk}

\authorinfo{Don Syme}
           {Microsoft Research Cambridge}
           {don.syme@@microsoft.com}

\maketitle

\begin{abstract}
Sequencing of effectful computations can be neatly captured using monads and elegantly written using 
|do| notation. In practice such monads often allow additional ways of composing computations, 
which have to be written explicitly using combinators.

We identify joinads, an abstract notion of computation that is stronger than monads and captures
many such ad-hoc extensions. In particular, joinads are monads with three additional operations: 
one of type |m a -> m b -> m (a, b)| captures various forms of \textit{parallel composition}, 
one of type |m a -> m a -> m a| that is inspired by \textit{choice} and one of type |m a -> m (m a)| 
that captures \textit{aliasing} of computations. Algebraically, the first two operations form a 
near-semiring with commutative multiplication.

We introduce |docase_| notation that can be viewed as a monadic version of |case|. Joinad laws
imply various syntactic equivalences of programs written using |docase_| 
that are analogous to equivalences about |case|. Examples of joinads that benefit from the notation
include speculative parallelism, waiting for a combination of user interface events, but also 
encoding of validation rules using the intersection of parsers. 
\end{abstract}

\category{D.3.3}{Language Constructs and Features}{Control structures}
\category{F.1.2}{Models of Computation}{Parallelism and concurrency}

\terms
Languages, Theory

% \keywords
% keyword1, keyword2

% ==================================================================================================

\section{Introduction}
Monads are traditionally used for embedding sequential computations into lazy functional code, 
but many recent uses go well beyond sequencing of state or computations. Monads have been used for 
the exact opposite---to explicitly specify parallelism. This is done by taking a core sequential 
monad and adding combinators that increase the expressive power beyond sequencing.

Monads for concurrent \cite{poorman} and parallel programming \cite{parmonad} support forking 
and synchronizing computations \cite{chp-monad}. A monad for user-interface programming 
includes combinators for merging events from various sources \cite{imperative-streams}. These 
ad-hoc extensions are extremely useful, but they are not uniform. Developers have to understand 
different combinators for every computation and they lose the syntactic support provided by |do| notation.

This paper discusses \textit{joinads}---an abstract notion of computations that extends monads.
Joinads capture a pattern that appears in many monadic computations with an additional expressive 
power that goes beyond sequencing. We presented an earlier form of joinads in \fsharp \cite{joinads}. 
This paper makes several novel findings, but our first contribution to Haskell is similar to the 
earlier work in \fsharp:

\begin{itemize}
\item  We add language support for important kinds of computations, including 
  parallel, concurrent and reactive programming. This is done via a lightweight, reusable language 
  extension that builds on core functional concepts such as pattern matching.

\end{itemize}
This paper simplifies the concept of joinad and requires that every joinad is also a monad (just like
every group is also a monoid). In Haskell, we also relate several ideas that already disconnectedly 
exist. The specific new contributions of this paper are:

\begin{itemize}
\item We present |docase_| notation for Haskell\footnote{Prototype version is available at 
  \texttt{http://github.com/tpetricek/ Haskell.Joinads} and we plan to submit a GHC patch in the 
  future. } (Sections \ref{sec:motivation}, \ref{sec:extension}) 
  that allows programming with monadic computations extended with aliasing, parallel composition
  and choice. We specify laws about these operations to guarantee that |docase_| keeps the familiar 
  semantics of pattern matching using |case| (Section \ref{sec:reasoning}).

\item To demonstrate the usefulness of the extension, we consider parsing
  (Section \ref{sec:intro-combining-parsers}), GUI programming using events
  (Section \ref{sec:intro-choosing-events}), lightweight concurrency
  (Section \ref{sec:intro-commit-poorman}), and a parallelism monad with
  support for speculative parallelism (Section \ref{sec:intro-aliasing-parallel}).

\item The type of the above computations is captured by a \ident{Joinad} type class (Section 
  \ref{sec:extension-typeclass}). It relates type classes that have been already proposed for 
  Haskell. Based on our experience, we propose and discuss several adjustments to the Haskell base 
  library and laws required by the type classes we combine (Section \ref{sec:proposals}). 

\item A joinad is an abstract computation that extends monads with three operations.
  Deriving the laws about the three operations (Section \ref{sec:laws}) reveals that two of
  the operations form an algebraic structure known as a \textit{near-semiring}.

\end{itemize}
The following section demonstrates the usefulness of |docase_| in the context 
of parallel programming.

% ==================================================================================================

\section{Motivating example}
\label{sec:motivation}

Consider the following problem: we are given a tree with values in leaves and we want to test
whether a predicate holds for all values in the tree. This can be implemented as a recursive function:

\begin{code}
all :: (a -> Bool) -> Tree a -> Bool

all p (Leaf v)           = p v
all p (Node left right)  = all p left && all p right
\end{code}
The execution of the two recursive calls could proceed in parallel. Moreover, when one of the 
branches completes returning |False|, it is not necessary to wait for the completion of the other 
branch as the overall result must be |False|.

Running two branches in parallel can be specified easily using strategies \cite{strategies-new, strategies-old}, 
but adding short-circuiting behaviour is challenging. Using the |docase_| notation and a monad for 
parallel programming, the problem can be solved as follows:

\begin{code}
all :: (a -> Bool) -> Tree a -> Par Bool

all p (Leaf v)           = return (p v)
all p (Node left right)  = 
  docase_ (all p left, all p right) of
    (False, ?)    -> return False
    (?, False)    -> return False
    (allL, allR)  -> return (allL && allR)
\end{code}
The function builds a computation annotated with hints that specify how to evaluate it in parallel 
using the |Par| monad \cite{parmonad} extended with the support for non-deterministic choice 
operator \cite{parmonad-cancellation}.

To process sub-trees in parallel, the snippet constructs two computations (of type |Par Bool|) 
and uses them as arguments of |docase_|. Patterns in the alternatives correspond to individual
computations. A special pattern |?| denotes that a value of the monadic computation does not 
have to be available for the alternative to be selected. When the processing of the left subtree 
completes and returns |False|, the first alternative can be selected immediately, because the 
result of the second computation is not required.

If the result of the left subtree is |True| and the right one has not completed, none of 
the alternatives are immeriately enabled. After the right subtree is processed, one of the last two alternatives 
can be selected. The choice operator added to the |Par| monad is non-deterministic, so the 
programmer needs to provide alternative clauses that produce the same result in case of race.
We return to this topic in Section~\ref{sec:intro-aliasing-parallel}, but it is, the case in 
the above example.

The selection between alternative clauses is done using the \textit{choice} operator. Note that the result 
of each computation is used in two independent alternatives. Evaluating the argument repeatedly 
would defeat the purpose of |docase_|, so the translation uses the \textit{aliasing} operator to avoid 
this. The third alternative combines two computations, which is achieved using \textit{parallel
composition} operator provided by the |Par| monad.

The translation of |docase_| is more complex than of the |do| notation. This is not
a bad thing---the notation can be used to write programs that would otherwise be very complex. 
In the above example, developers would typically write the solution in a more imperative style 
shown in Appendix~\ref{sec:appendix-shortcircuit}. The length of the explicit version is 21 lines 
compared to 6 line in the version above. 

% ==================================================================================================

\section{Introducing docase}
This section introduces |docase_| using four examples. We first consider |docase_|
expressions with a single alternative that can be also written using \textit{zip comprehensions} 
\cite{comprefun} and then gradually add remaining features. A formal 
definition is shown in Section~\ref{sec:extension}.

% --------------------------------------------------------------------------------------------------

\subsection{Parallel composition of parsers}
\label{sec:intro-combining-parsers}
Parsers are a common example of monads. A parser is a function: when supplied with an input, it 
returns a parsed value and the remaining unconsumed input. The following definition largely follows
the one by Hutton and Meijer \cite{parsingtutorial}:

\begin{code}
newtype Parser a = P (String -> [(a, Int, String)])
\end{code}
Compared to standard parsers, there is one notable difference. In addition to the parsed result
and unconsumed input, the result also contains |Int| value, which denotes the number of consumed
characters. This will be needed later. A parser can be made an instance of \ident{Monad} to allow 
sequential composition and an instance of \ident{MonadPlus} to support choice. A more interesting 
question is, what does a parallel composition of parsers mean:

\begin{figure}
\begin{code}
instance MonadZip Parser where 
  mzip (P p1) (P p2) = P (\inp ->
    [ ((a, b), num1, tail1) |
         (a, num1, tail1) <- p1 inp,
         (b, num2, tail2) <- p2 inp, num1 == num2 ])
\end{code}
\caption{Instance of \ident{MonadZip} for parsers}
\label{fig:parser-monadzip}
\end{figure}

\begin{code}
mzip :: Parser a -> Parser b -> Parser (a, b)
\end{code}
Judging by the type, the |mzip| operation could be implemented in terms of |>>=| and |return|. 
This implementation would not, in general, obey the laws we require. We give more details in 
Section~\ref{sec:laws-monadzip}. For parsers, the |mzip| operation parses the input using both parsers and then 
returns all combination of values such that the two parsers consumed the same number of input 
characters. The meaning of this operation is that it creates a parser for a language that is an 
\textit{intersection} of languages described by the two parsers.

This implementation of |mzip| for parsers is shown in Figure~\ref{fig:parser-monadzip}. It
applies the two parsing functions to the same input and then returns all combinations for which
the predicate |num1 == num2| holds. An alternative implementation could compare the tails, but
that would be inefficient and would not work for infinite inputs.

The function belongs to the \ident{MonadZip} type class that has been added to GHC as part of a recent
implementation of \textit{monad comprehensions}. Monad comprehensions \cite{comprehendingmonads} 
generalize list comprehensions to work with an arbitrary monad. The recent extension
\cite{bringbackmc, comprefun} also generalizes grouping and ordering \cite{groupordercompre} and
syntax for zipping (\textit{zip comprehensions}), hence the name |mzip|. To demonstrate the 
parallel between |docase_| and generalized monad comprehensions, we start with an example written 
using both notations.

\paragraph{Example.}
Cambridge telephone numbers can be specified as strings satisfying three independent rules: 
they consist of 10 characters, contain only digits and they start with the prefix 1223. The following
snippet shows how to encode this rule using both \textit{parallel monad comprehensions} and 
the |docase_| notation:

\begin{code}
valid = docase_ (  many (sat isDigit), 
                   replicateM 10 item,
                   startsWith (string "1223") )
  of (num, _, _) -> return num

valid = [ num  | num  <- many (sat isDigit) 
               | _    <- replicateM 10 item
               | _    <- startsWith (string "1223") ]
\end{code}
The three arguments of the |docase_| construct are combined using the |mzip| function. In zip 
comprehensions, the same role is played by the bar symbol. If the parsers succeed, they 
return the same string, so the snippet only needs the result of a single parser.
The |docase_| snippet ignores other values using |_| patterns instead of |?| patterns.
The |?| pattern is special and it specifies that a value is not required, which 
means that the parser can fail. Conversely, the |_| pattern requires the parser to 
succeed, but then ignores the value. 

The |docase_| notation makes it possible to write everything that can be written using 
zip comprehensions in a style similar to |do| notation, but it also adds additional expressive 
power in a different way than generalized monad comprehensions.
 
\paragraph{Desugaring.}
The desugaring of |docase_| in the simple case shown above is essentially the same as desugaring 
of parallel monad comprehensions. In the translation, the |mzip| operation is written as |mzip_|. 
The reason for this will become clear when we discuss the algebraic theory behind joinads 
in Section \ref{sec:theory-algebra}.

\begin{code}
validPhone = 
    ((many (sat isDigit) mzip_ times item 10) 
        mzip_ startsWith (string "1223")) >>= \x ->
            case x of ((num, _), _) -> return num
\end{code}
The actual translation includes several additional features that are explained later, but
they have no effect on the meaning. The expression combines all arguments of |docase_| 
(or all parallel generators of a comprehension) using the |mzip_| operation. The result is 
a combined value of type |Parser ((String, String), String)|. This value is passed as an input to 
|>>=|. The lambda function decomposes the tuple using original patterns of the |docase_| 
alternative. In this example, the pattern never fails, so other cases are omitted. The body of 
the lambda creates a parser that succeeds and returns the parsed valid phone number.

Next, consider a case where |docase_| has multiple alternatives, but each contains only a single
binding (a pattern other than |?|).

% --------------------------------------------------------------------------------------------------

\subsection{Choosing between events}
\label{sec:intro-choosing-events}

The examples in this section are based on the imperative stream monad developed by Scholz
\cite{imperative-streams}. Imperative streams are ``a generalization of the IO monad suitable for
synchronous concurrent programming''. An imperative stream produces zero or more values and 
performs side-effects at certain (discrete) times. Our example uses a simplified model of 
\textit{event streams} with type |Evt a| that do not allow side-effects.

Event streams can be viewed as functions that take a time indicating when they are started and return a list of 
time value pairs representing the occurrences of the event. They are instances of the \ident{Monad} 
type class. The |return| operation creates an event stream that occurs exactly once at the time when 
it was started. The behaviour of the |>>=| operation is as follows: when the input event occurs, the 
event stream returned by |>>=| starts producing the occurrences of the event stream generated by the 
function passed to |>>=| until the next occurrence of the input event.

In addition to the operations of \ident{Monad}, event streams can also implement a monadic or--else
operation representing a choice:

\begin{code}
morelse :: Evt a -> Evt a -> Evt a
\end{code}
The resulting event stream occurs whenever any of the two arguments occur. When both of the 
arguments occur at the same time, then the returned value is the value produced by the first (left)
argument. As explained later (Section \ref{sec:reasoning}), this natural left bias of the operation is 
required by a law about |morelse|.

\paragraph{Example.} Assume that the user can create objects by clicking and can use the Shift
key to switch between two types of objects. The user interface provides event 
streams |shiftDown| and |shiftUp| that occur when Shift is pressed and released; an event 
stream |load| occurs once when the application starts and |mouseClick| occurs each time the 
mouse button is pressed.

The following snippet creates an event stream of type |Evt Bool| that occurs each time a mouse 
button is clicked. The value carried by the event is a flag denoting whether Shift was
pressed:

\begin{code}
shiftClicks = docase_ (load, shiftUp, shiftDown) of
  (a, ?, ?)  -> fmap (const False) mouseClick
  (?, u, ?)  -> fmap (const False) mouseClick
  (?, ?, d)  -> fmap (const True) mouseClick
\end{code}
When one of the events passed to |docase_| produces a value, the resulting event starts producing
values generated by one of the alternatives (|True| or |False| whenever mouse is clicked).
Each of the alternatives matches on a single event stream and ignores the values of other event 
streams using the |?| pattern. The variables bound by the patterns are not used, so we could use 
|_|, but naming the variables makes the example easier to follow.

\paragraph{Desugaring.}
The desugared code is shown below. Each alternative binds only on a single event, 
so the translation does not use the |mzip| operation. The |morelse| operation is abbreviated 
as |morelse_|:

\begin{code}
shiftClicks = 
  (load >>= \a -> fmap (const False) mouseClick)  morelse_
  (shiftUp >>= \u -> fmap (const False) mouseClick) morelse_
  (shiftDown >>= \d -> fmap (const True) mouseClick)
\end{code}
The translator processes alternatives independently and then merges them using |morelse_|. The 
event stream corresponding to a binding pattern (pattern other than |?|) is passed as the first 
argument to |>>=|. The provided function contains the body of the alternative. 
The example is simplified, because patterns in the alternatives do not fail. If pattern matching
could fail, the event stream should continue behaving according to the last selected alternative. To
encode this behaviour, the translation needs one more extension (Section \ref{sec:intro-commit-poorman}).

\begin{figure}
\begin{code}
^sm(unit v)^sub(s)        = \t -> if s == t then Just v else Nothing

^sm(a mzip_ b)^sub(s)     = \t -> case (^sm(a)^sub(s) t, ^sm(b)^sub(s) t) of
  sp_ sp_  (Just v^sub(1), Just v^sub(2)) -> Just(v^sub(1), v^sub(2)); sp_ _ -> Nothing

^sm(a morelse_ b)^sub(s)  = \t -> case (^sm(a)^sub(s) t, ^sm(b)^sub(s) t) of
           (Just v^sub(1), _) -> Just v^sub(1); sp_ (_, o^sub(2)) -> o^sub(2)

^sm(a >>= f)^sub(s)       = \t -> case (last t smp_ ^sm(a)^sub(s)) of
           (Just(t^sub(1), v^sub(1))) -> ^sm(f v^sub(1))^sub(t^sub(1)) t; sp_ _ -> Nothing
  where  last 0 _   = Nothing
         last t sf  = case sf t of  Just v -> Just (t, v)
                                    _ -> last (t - 1) sf
\end{code}
\caption{Semantics of imperative streams}
\label{fig:imperativestream-semantics}
\end{figure}

\paragraph{Semantics.} Showing a complete implementation of event streams is beyond the scope of
this article. We present a semantics that defines the implementation and can be used to verify 
that the operations obey joinad laws. The semantics follows the original definition of imperative 
streams \cite{imperative-streams}. Instead of using lists, we model event occurrences as a 
function returning |Maybe| value:

\begin{code}
^sm(Evt a)^sub(T) :: T -> Maybe a
\end{code}
The time $T$ is a discrete value. When applied to a starting time $t \in T$, the semantic function 
gives a partial function that returns |Just v| if the event occurs at the specified time.
The semantics of \ident{Monad} operations, |mzip_| and also |morelse_| is given in 
Figure \ref{fig:imperativestream-semantics}.
The semantics of |mzip_| and |morelse_| follow a similar pattern. At given time, they combine 
both, or take the leftmost value if the required values are available. Finally, the result of monadic
bind (|>>=|) behaves as an event stream generated by the last occurrence of the input event.

Using this semantic model, we could derive an implementation using the techniques developed recently 
for functional reactive programming (FRP) by Elliott \cite{push-pull-frp}. Compared to other 
approaches, imperative streams give a simple model based just on discrete events, but the |docase_|
notation can be also used when programming with continuous values.

% --------------------------------------------------------------------------------------------------

\subsection{Aliasing parallel computations}
\label{sec:intro-aliasing-parallel}

This section explains the use of the last of the three joinad operations: |malias| which 
represents aliasing of computations. The operation gives the monad (joinad) more control of
the control-flow by abstracting away certain aspect of the evaluation mechanism.
The parallel |all| function in Section~\ref{sec:motivation} 
critically relied on this feature, so we demonstrate the problem using the parallelism monad.

A value of type |Par a| represents a computation that can be evaluated (using some parallel evaluator) 
to get a value of type |a|. Parallel computations are instances of \ident{Monad}. The |return|
operation creates a computation that immediately returns and |>>=| 
evaluates the argument and then evaluates the result produced by a continuation.
The implementation of |mzip| for |Par a| starts two computations in parallel and produces a value 
when they both complete; |morelse| represents a non-deterministic choice and completes when the first 
of the two computations produce a value.

\begin{figure}
\begin{code}
^sm(unit v)        = \t -> (t, v)

^sm(mzero)         = \t -> (inf_, bot_)

^sm(a mzip_ b)     = \t -> (max t^sub(1) t^sub(2), (v^sub(1), v^sub(2)))
	where  ((t^sub(1), v^sub(1)), (t^sub(2), v^sub(2))) = (^sm(a) t, ^sm(b) t)

^sm(a morelse_ b)  = \t -> (min t^sub(1) t^sub(2), v)
	where  ((t^sub(1), v^sub(1)), (t^sub(2), v^sub(2))) = (^sm(a) t, ^sm(b) t)
	       v | t^sub(1) <= t^sub(2) = v^sub(1) | otherwise = v^sub(2)

^sm(a >>= f)       = \t -> ^sm(b) s
	where  (s, v) = ^sm(a) t; sp_ b = f v

^sm(malias a)      = \t -> (\t^sub(2) -> (max t^sub(1) t^sub(2), v))
	where (t^sub(1), v) = ^sm(a) t
\end{code}
\caption{Semantics of futures}
\label{fig:future-semantics}
\end{figure}

\paragraph{Example.} Consider some calculation, that uses a main function, |calc|, 
and two alternative heuristic functions, |alt1| and |alt2|. In order to continue, we need the 
result of the main function and one heuristic. Using |docase_|, this can be written as follows:

\begin{code}
calcAlt inp = docase_ (calc inp, alt1 inp, alt2 inp) of
  (a, b, ?) -> return (a, b)
  (a, ?, c) -> return (a, c)
\end{code}
Note that the first argument is bound to a variable |a| in both of the alternatives. The desired 
operational meaning is that the expression starts all three computations in parallel and then waits 
until computations required by some alternative complete. Using the logic described so far, the 
snippet might be translated as follows:

\begin{code}
calcAlt inp = 
  (calc inp) mzip_ (alt1 inp) >>= \ (a, b) -> return (a, b) morelse_
  (calc inp) mzip_ (alt2 inp) >>= \ (a, c) -> return (a, c)
\end{code}
This does not give the required behaviour. The code creates a computation that 
starts four tasks -- the two alternative heuristics and two instances of the main
computation. Eliminating a common subexpression |calc inp| does not solve the problem. The value 
|Par a| obtained from |calc inp| represents a recipe for creating a computation, as opposed to 
a running task. When used repeatedly, it starts a new computation.

\paragraph{Desugaring.} To get the desired semantics, we need some way to start the computation
once and get an aliased computation that can be used multiple times. This is exactly
what the |malias| operation provides. It can be best explained by looking at the type 
signature together with the implementation for the |Par a| monad:

\begin{code}
malias :: Par a -> Par (Par a)
malias p = do 
  v <- spawn p
  return (get v)
\end{code}
The implementation starts a given computation using the |spawn| function, which returns a 
mutable variable that will contain the result of the computation when it completes. Then 
it returns a computation of type |Par a| created using the |get| function. When used, the 
computation blocks until the variable is set.

Equipped with this operation, the desugaring can create an aliased monadic computation for each
of the |docase_| arguments and then use the aliased computations repeatedly:

\begin{code}
calcAlt inp = 
  malias (calc inp) >>= \c0 ->
  malias (alt1 inp) >>= \c1 ->
  malias (alt2 inp) >>= \c2 ->
  c0 mzip_ c1 >>= \ (a, b) -> return (a, b) morelse_
  c0 mzip_ c2 >>= \ (a, b) -> return (a, b)
\end{code}
This version gives the desired operational behaviour. Each of the three arguments of |docase_| 
is started exactly once (in the implementation of |malias|). The body is composed using 
computations that merely represent aliases (using a mutable variable internally). In 
particular, both of the alternatives combined using |morelse_| use the alias |c0| that refers
to the |calc| computation.

\paragraph{Semantics.} To describe the example more formally, we present a simple semantics.
It can be used to verify that the joinad laws (Section \ref{sec:laws}) hold for the |Par a| type. 
Here, a computation is modelled as a function that takes a time when the computation is started and 
returns a time when it completes together with the result:

\begin{code}
^sm(Par a) :: T -> (T, a)
\end{code}
The semantics is shown in Figure~\ref{fig:future-semantics}.
Operations of \ident{Monad} as well as |mzip_| and |morelse_| behave as already informally described.
The |malias| operation applies the semantic function to a given computation with the starting 
time of |malias| as an argument. The resulting computation finishes either at 
the completion time or at the time when it is created, whichever happens later.

The semantics does not capture the number of computations running in parallel, so it is only useful for
considering joinad laws. The next section describes a variation where computations have 
side-effects. In that case |malias| becomes more important, because it avoids duplication
of side-effects. For some monads, such as |IO|, the |malias| operation can be defined as follows:

\begin{code}
malias op = op >>= return . return
\end{code}
This definition could be used for any monad, but it would not always give useful behaviour.
For example, in |Par a|, it would unnecessarily sequentialize all computations.

\paragraph{Nondeterminism.} The semantics presented in Figure~\ref{fig:future-semantics} is 
deterministic, but in reality, this is not the case. We could add small $\delta$ to all operations 
involving time. The interesting case is the |morelse_| operation, where the value (second element 
of the tuple) depends on the time. This means that the operation introduces non-determinism.

To keep programs simple and deterministic, we follow the approach used by Elliott for the unambiguous 
choice (|unamb|) operator \cite{push-pull-frp}. The |morelse| operation can be used only when the 
two arguments are \textit{compatible}:

\begin{code}
compatible a b = forall_ t {-". \ "-} (t^sub(1) == inf_) || (t^sub(2) == inf_) || (v^sub(1) == v^sub(2))
	where  (t^sub(1), v^sub(1)) = ^sm(a)^sub(t); sp_ (t^sub(2), v^sub(2)) = ^sm(b)^sub(t)
\end{code}
When started at the same arbitrary time, the two operations are required to produce the same value if they
both complete. As discussed in the next section, an operation that never completes can be created 
using the |mzero| operation and represents an alternative clause with failing patterns. 
The condition could be reformulated in terms of |docase_| alternatives. It is not difficult to 
see that the condition holds for the motivating example from Section~\ref{sec:motivation}.

% --------------------------------------------------------------------------------------------------

\subsection{Committing to a concurrent alternative}
\label{sec:intro-commit-poorman}

The final simplification made in the previous example was that the patterns of |docase_| alternatives 
never failed. This aspect can be demonstrated using a monad based on Poor Man's Concurrency 
Monad developed by Claessen \cite{poorman}. A value of type |Concur m a| represents a computation 
that will eventually produce a value of type |a| and may produce effects in a monad |m| along the way. 

The monad is similar to parallel computations from the previous section. To give a concrete semantics, 
assume that the underlying monad is a writer monad using monoid |M| to keep the state. The semantics from 
the previous section could be extended by adding state to the result:

\begin{code}
^sm(Concur (Writer M) a) :: T -> (T, a, M)
\end{code}
The semantics from Figure \ref{fig:future-semantics} can be extended in a straightforward way to use
this function. Unlike |Par a|, the implementation of |Concur m a| does not actually run computations in 
parallel. It emulates concurrency by interleaving of steps. This means that the |Concur m a| monad is 
deterministic and the time |T| represents the number of primitive steps. In order to support patterns 
that may fail, the type also provides an operation |mzero| representing a failure:

\begin{code}
mzero :: Concur m a
\end{code}
The operation is defined for standard monads that implement the \ident{MonadPlus} type class. For the
Poor Man's Concurrency monad, the operation creates a computation that never produces a value.

\paragraph{Example} Consider a function that concurrently downloads data from two servers. When some
data is not available, the function returns |Nothing|. When both servers produce a value, the function
returns |Just| containing a tuple, but only when the values are compatible. When data is incompatible,
the function should fail.

\begin{code}
downloadBoth :: Concur IO Bool
downloadBoth = docase_ (dl1, dl2) of
  (Just a, Just b) -> do
    lift (print "Got both values")
    if compatible a b then return Just(a, b) else mzero
  (_, _) -> do
    lift (print "Some value missing")
    return Nothing
\end{code}
The first alternative of |docase_| matches when both of the computations produce |Just| value.
The body prints a message (the |lift| function lifts a value |IO a| into |Concur IO a|) and then 
returns |Just| or fails by returning |mzero|. The second alternative handles any values and returns 
|Nothing| after printing a message.

Tullsen \cite{firstlcasspats} suggested returning |mzero| when pattern matching fails. When it 
succeeds, the original body is returned. For simplicity, we omit |malias|:

\begin{code}
(dl1 mzip_ dl2 >>= \t -> case t of 
    (Just a, Just b) -> do smp_ ...
    _ -> mzero) morelse_
(dl1 mzip_ dl2 >>= \t -> do smp_ ...)
\end{code}
An intuitive expectation about pattern matching that we want to keep for joinads is that 
|->| behaves as a \textit{commit point}. Once arguments match patterns of some alternative, the 
code will execute this alternative and not any other. However, this is not the case with the
desugaring above. When the function downloads two incompatible values, it prints ``Got both values''.
Then it fails and starts executing the second clause, printing ``Some values missing''.

\paragraph{Desugaring} To get the desired behaviour, the desugaring needs to add an additional
level of wrapping. Instead of just returning the body, we wrap the body using |return|:

\begin{code}
(dl1 mzip_ dl2 >>= \t -> case t of 
    (Just a, Just b) -> return (do smp_ ...)
    _ -> mzero) morelse_
(dl1 mzip_ dl2 >>= \t -> 
    return(do smp_ ...)) >>= id
\end{code}
The cases where pattern matching succeeded now contain just a call to |return| with the body
of the alternative as an argument and the cases where the pattern matching fails contain |mzero|.
This means that the type of values aggregated using |morelse_| is |m (m a)|. Additionally,
all of them are either of the form |m >>= return . f| or |m >>= mzero|.
The result of |morelse_| has the same type as its arguments, so the overall result also has a type
|m (m a)|. It represents a monadic value that wraps (or produces) body(ies) that have
been selected. To create a computation that actually runs the body, the desugaring inserts 
|>>= id| at the end of the translated expression. 

% ==================================================================================================

\section{Language extension}
\label{sec:extension}

This section formally defines the |docase_| notation including its syntax, typing rules and the 
translation. 

% --------------------------------------------------------------------------------------------------

\subsection{Syntactic extension}
\label{sec:extension-syntax}

The extension adds an additional syntactic case to Haskell expression $e$. It also 
defines a category of docase alternatives $a$ and docase patterns $w$ that include 
the additional special pattern |?| (ignore):

\begin{code}
p  =  x | (p^sub(1), ..., p^sub(n)) | ...            {-"\text{Ordinary patterns}"-}

w  =  ?                                              {-"\text{Monadic ignore pattern}"-}
   |  p                                              {-"\text{Monadic binding pattern}"-}

a  =  (w^sub(1), ..., w^sub(n)) -> e                 {-"\text{Docase alternative ($\exists i : w_i \neq \: ?$)}"-}

e  =  docase_ (e^sub(1), ..., e^sub(n)) of  sp_ sp_  {-"\text{Docase expression with}"-}
        a^sub(1); ...; a^sub(k)                      {-"\text{$k$ alternatives ($k \geq 1$)}"-}
\end{code}
The |docase_| expression is similar to standard |case|. A docase pattern $w$ can be standard Haskell 
patterns $p$ or a special \textit{ignore pattern} written as |?|. A docase alternative $a$ must
contain at least one binding pattern (pattern other than |?|), because there is no easy way to 
construct monadic computation that succeeds when all other computations fail. Finally, the |docase_| 
expression must include at least one alternative.

% --------------------------------------------------------------------------------------------------

\subsection{Joinad type class}
\label{sec:extension-typeclass}

The |docase_| syntax operates on values of some type |m a| that is an instance of a \ident{Joinad} 
type class. The type class provides operations required by the |docase_| translation. 
Figure~\ref{fig:joinad-classes} shows the definition of \ident{Joinad}. The definition just 
combines several classes that already exist in various Haskell extensions and packages. 

\begin{itemize}
\item \ident{MonadZero} and \ident{MonadOr} are defined in a \ident{MonadPlus} reform proposal
\cite{monadplusreform}. It aims to distinguish between cases when the (monoidal) operation is 
unbiased (\ident{MonadPlus}) and when it has a left bias (\ident{MonadOr}). For joinads, we 
require left bias, but we express the law slightly differently (Section~\ref{sec:laws-monador}).

\item \ident{MonadZip} is defined by a GHC extension that adds \textit{monad comprehensions}
\cite{bringbackmc, comprefun}. The extension adds new expressive power that is not available with 
the |do| notation \cite{parcomprefun}. The |docase_| syntax uses the \ident{MonadZip} type class in 
a similar way as \textit{parallel monad comprehension} and provides similar expressivity using 
a syntax similar to the |do| notation.

\item \ident{MonadAlias} is similar to the \ident{Extend} type class from the comonad 
package \cite{comonadpkg}. The only difference is that we require the type to also be a monad.

\end{itemize}
The theoretical background and the laws that are required to hold about the operations are discussed 
in Sections~\ref{sec:reasoning} and \ref{sec:theory}. The next 
two sections complete the specification of the language extension.

\begin{figure}
\begin{code}
class Monad m => MonadZero m where
   mzero :: m a

class MonadZero m => MonadOr m where
   morelse :: m a -> m a -> m a

class Monad => MonadZip m where
  mzip :: m a -> m b -> m (a, b)

class Monad m => MonadAlias m where
  malias :: m a -> m (m a)

class (MonadAlias m, MonadZip m, MonadOr m) 
  => Joinad m
\end{code}
\caption{ The definition of \ident{Joinad} type class. }
\label{fig:joinad-classes}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsection{Typing rules}
\label{sec:extension-typing}

Similarly to other syntactic sugar in Haskell \cite{groupordercompre}, the |docase_| expression 
is type-checked before translation. The typing rules are shown in Figure \ref{fig:typing-rules} 
and are defined in terms of three judgements.

The judgement $\vdash w : \tau \Rightarrow \Delta$ for patterns is similar to the one used by
Wadler and Peyton Jones \cite{groupordercompre}. It specifies that a pattern $w$ of type $\tau$ binds 
variables of the environment $\Delta$. An ignore pattern does not bind any variables (\textsc{Ign}); 
a variable pattern binds a single variable (\textsc{Var}) and a tuple pattern binds the union of 
variables bound by sub-patterns (\textsc{Tup}).

The judgement $\Gamma, m, \bar{\tau} \vdash a \leadsto \alpha $ is more interesting. It 
checks the type of an individual alternative of the |docase_| construct. The judgement is provided 
with an environment $\Delta$, a \ident{Joinad} type $m$ and a list of types of 
|docase_| arguments. It type-checks the alternative and yields the type of values produced by the
body of the alternative (\textsc{Alt}). The body $e$ of each alternative must have the same monadic 
type $m$ (of kind |* -> *|) as the |docase_| arguments. 

Finally, $\Gamma \vdash a : \tau$ extends the standard type-checking procedure
for Haskell expressions with a rule for |docase_| (\textsc{Doc}). When the type of arguments is 
a \ident{Joinad} type $m$ (of kind |* -> *|) applied to some type argument and all 
alternatives yield the same return type $\alpha$, then the overall type of the expression is 
$m \ \alpha$.

% --------------------------------------------------------------------------------------------------

\subsection{Translation}
\label{sec:extension-translation}

After type-checking, the |docase_| notation is translated to applications of functions provided by the 
\ident{Joinad} type class. The desugaring is defined using two functions:

\begin{code}
d^tsm(-)  :: e -> e
c^tsm(-)  :: a -> [id] -> e
\end{code}
The first function takes an expression. If the argument is the |docase_| expression, the function
produces an expression that does not contain |docase_| at the top-level. The second function is used
for translating alternatives of |docase_|. It takes a list of identifiers that refer to the arguments
of the |docase_| expression. The translation is defined by the following two rules:

\begin{code}
d^tsm(docase_ (e^sub(1), ..., e^sub(n)) of a^sub(1); ...; a^sub(k)) =
  malias e^sub(1) >>= \v^sub(1) -> sp_ ... sp_ malias e^sub(n) >>= \v^sub(n) ->
  (c^tsm(a^sub(1)) [v^sub(1), ..., v^sub(n)] morelse_ ... morelse_ c^tsm(a^sub(n)) [v^sub(1), ..., v^sub(n)]) >>= id

lsp_

c^tsm((w^sub(1), ..., w^sub(n)) -> e) [v^sub(1), ..., v^sub(n)] = 
  v^sub(1) mzip_ ... mzip_ v^sub(m) >>= \x -> case x of 
    (p^sub(1), ..., p^sub(m))  -> return e
    otherwise                  -> mzero

  where  [ (p^sub(1), v^sub(1)), ..., (p^sub(m), v^sub(m)) ] = 
           [ (w^sub(i), v^sub(i)) | i <- 1 ... n, w^sub(i) neq_ ?]
\end{code}
The arguments (|e^sub(1), .., e^sub(n)|) of |docase_| are first passed to |malias|, which
constructs a value of type |m (m a)|. The |>>=| operator provides the lambda with 
values |v^sub(i)| that represents the aliased computations. The function |c^tsm(-)| takes an alternative
and the aliased computations and produces values of type |m (m a)| that represent monadic values 
carrying bodies to be executed. The results are combined using the |morelse_| operation, which 
gives a value of type |m (m a)|. The last binding passes it to the identity function to execute 
the body of the selected alternative.

To translate an alternative, we identify which of the arguments are matched against
a binding pattern. These computations are combined using the |mzip_| operation. The resulting 
computation produces tuples such as |(a, (b, c))|. As discussed later, the |mzip_| operation is 
associative, so the order of applying |mzip_| does not matter. Values produced by the combined monadic computation 
are matched against a pattern re-constructed from \textit{binding patterns} of the alternative. 
When a value matches, the body is wrapped using |return|. Otherwise, the alternative 
reports a failure using |mzero|.

% --------------------------------------------------------------------------------------------------

\begin{figure}
\begin{equation*}
\fbox{$\vdash w : \tau \Rightarrow \Delta$}
\end{equation*}

\begin{equation*}
\inferrule
  { }
  {\vdash \text{?} : \tau \Rightarrow \{ \}}
\quad(\textsc{Ign}) \ \ \ \ \ \ \ \
\inferrule
  { }
  {\vdash x : \tau \Rightarrow \{ x : \tau\}}
\quad(\textsc{Var})
\end{equation*}

\begin{equation*}
\inferrule
  {\vdash w_i : \tau_i \Rightarrow \Delta_i}
  {\vdash (w_1, \ldots, w_n) : (\tau_1, \ldots, \tau_n) \Rightarrow \Delta_1 \cup \ldots \cup \Delta_n}
\quad(\textsc{Tup})
\end{equation*}

\begin{equation*}
\fbox{$\Gamma, m, \bar{\tau} \vdash a \leadsto \alpha $}
\end{equation*}

\begin{equation*}
\inferrule
  {\vdash w_i : \tau_i \Rightarrow \Delta_i  
     \\ \Delta_1 \cup \ldots \cup \Delta_n \vdash e : m \ \alpha  }
  {\Gamma, m, \bar{\tau} \vdash (w_1, \ldots, w_n) \rightarrow e \leadsto \alpha }
\quad(\textsc{Alt})
\end{equation*}

\begin{equation*}
\fbox{$\Gamma \vdash a : \tau$}
\end{equation*}

\begin{equation*}
\inferrule
  {\langle\textbf{Joinad} \ m \rangle \\ \Gamma \vdash e_i :m \ \tau_i 
    \\ \Gamma, m, \bar{\tau} \vdash a_i \leadsto \alpha }
  {\Gamma \vdash \textbf{docase} \ \bar{e} \ \textbf{of} \ a_1; \ldots; a_n : m \ \alpha}
\quad(\textsc{Jon})
\end{equation*}
\caption{ Typing rules for docase. }
\label{fig:typing-rules}
\end{figure}

% ==================================================================================================

\section{Reasoning about monadic pattern matching}
\label{sec:reasoning}

The |docase_| syntax intentionally resembles |case| syntax and we would like to guarantee 
that the operational behaviour is similar as well. The notation is used for working with values of an 
abstract type, so there is no concrete semantics. 

Figure~\ref{fig:transformations} shows syntactic transformations that must preserve
the semantics. In Section~\ref{sec:laws}, we find a set of laws that implies the equivalences
required here. Using a mathematical model, we proved that the equivalences follow from the primitive
laws using the Coq theorem prover\footnote{\texttt{http://www.cl.cam.ac.uk/\textasciitilde tp322/papers/docase.html}}. 
Finding a set of equivalences that permit proving the opposite implication 
(completeness) similarly to monad comprehensions \cite{comprehendingmonads} is left to future work.

\begin{itemize}
\item \textit{Binding equivalence} describes a degenerate case in which pattern matching uses
  a single alternative that always succeeds. It specifies that a specific use of |malias|
  does not affect the meaning of monadic binding.
  
\item \textit{Argument ordering} specifies that the order in which arguments and patterns are
  specified does not affect the meaning. This equation implies commutativity and associativity 
  laws of the |mzip_| operation.

\item Unlike the order of arguments, the order of clauses is important. The
  \textit{clause ordering} equivalence specifies that the |morelse_| operation is left-biased.

\item The equivalences \textit{alternative noninterference} and \textit{argument noninterference}
  specify that including additional failing clause or argument, respectively, has no effect on the meaning. (In 
  equation (4), the symbol $\bullet$ stands for a pattern that never succeeds.) The equations are
  manifested as laws that identify |mzero| as \textit{zero element} of |mzip_| and \textit{neutral
  element} of |morelse_|.

\item The next three equivalences describe the case when arguments are created in some special 
  way\footnote{The |map| operation can be defined as |>>= return| and is also called |liftM|.}.
  They define a group of \textit{naturality} properties of the |mzip_| operation.

\item The \textit{distributivity} equivalence requires that certain nested uses of |docase_| can 
  be flattened. This equivalence specifies that |mzip_| distributes over |morelse_|.
\end{itemize}

% ==================================================================================================

\section{Joinad laws}
\label{sec:laws}

This section discusses primitive laws about individual joinad operations that are 
implied by the above equivalences. First, we review the well-known monad laws that 
are also required for any joinad:
\begin{align*}
\munit \: a \bind f &\equiv f \: a \tag{left identity} \\
m \bind \munit &\equiv m \tag{right identity} \\
(m \bind f) \bind g &\equiv m \bind \lambda x \rightarrow f \: x \bind g \tag{associativity}
\end{align*}
Joinad also requires the |mzero| operation from \ident{MonadZero}. The value should behave as a 
zero element with respect to binding:
\begin{align*}
\mzero \bind f &\equiv \mzero \tag {left zero} \\
m \bind \lambda x \rightarrow \mzero &\equiv \mzero \tag{right zero}
\end{align*}
The \textit{left zero} law is generally accepted. The \textit{right zero} law is sometimes omitted, 
because it may not hold when $m$ is $\bot$, but the official documentation for \ident{MonadPlus}
\cite{monadplusdoc} includes it. All of these five laws are necessary to prove the 
equivalences in Figure~\ref{fig:transformations}.

% --------------------------------------------------------------------------------------------------

\begin{figure}
\begin{code}
lsp_
{-"\text{(1) Binding equivalence}"-}
  docase_ m of v -> e sp_ == sp_ do v <- m; e

lsp_
{-"\text{(2) Argument ordering}"-}
  docase_ (m^sub(1), ..., m^sub(n)) of
    (w^sub(1,pi1_) ... w^sub(1,pin_)) -> e^sub(1); ...
    (w^sub(k,pi1_) ... w^sub(k,pin_)) -> e^sub(k)
  {-"\text{(are equivalent for any permutation $\pi$ of $1 \ldots n$)}"-}

lsp_
{-"\text{(3) Clause ordering}"-}
    docase_ m of v -> e^sub(1); sp_ v -> e^sub(2)
==  docase_ m of v -> e^sub(1)

lsp_
{-"\text{(4) Alternative noninterference}"-}
    docase_ m of v       -> e^sub(1); sp_ pfail_  -> e^sub(2)
==  docase_ m of pfail_  -> e^sub(2); sp_ v       -> e^sub(1)
==  docase_ m of v       -> e^sub(1)

lsp_
{-"\text{(5) Argument noninterference}"-}
    docase_ (m, mzero) of (v, ?)                -> e^sub(1);      (v^sub(1), v^sub(2))  -> e^sub(2)
==  docase_ (mzero, m) of (v^sub(1), v^sub(2))  -> e^sub(2); sp_  (?, v)                -> e^sub(1)
==  docase_ m of v -> e^sub(1)

lsp_
{-"\text{(6) Matching units}"-}
    docase_  (return e^sub(1), return e^sub(2)) of (v^sub(1), v^sub(2)) -> e
==  case (e^sub(1), e^sub(2)) of (v^sub(1), v^sub(2)) -> e

lsp_
{-"\text{(7) Matching images}"-}
    docase_ (map f e^sub(1), map g e^sub(2)) of (v^sub(1), v^sub(2)) -> e
==  docase_ (e^sub(1), e^sub(2)) of (u^sub(1), u^sub(2)) -> e[v^sub(1) <- f u^sub(1), v^sub(2) <- g u^sub(2)]

lsp_
{-"\text{(8) Matching duplicate}"-}
    docase_ (a, a) of (u, v) -> e
==  docase_ a of u -> e[v <- u]

lsp_
{-"\text{(9) Distributivity}"-}
    docase_ (m, n^sub(1), n^sub(2)) of 
      (v, v^sub(1), ?) -> e^sub(1); sp_ v, ?, v^sub(2) -> e^sub(2)
==  docase_ (m, docase_ (n^sub(1), n^sub(2)) of
      (v^sub(1), ?) -> return (\v -> e^sub(1)); 
      (? , v^sub(2)) -> return (\v -> e^sub(2))) of (v, f) -> (f v)
\end{code}

\caption{ Syntactic transformations that preserve the semantics. }
\label{fig:transformations}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsection{MonadZip type class}
\label{sec:laws-monadzip}
This section discusses laws that are required about |mzip_| by joinads. The laws 
presented here are also a reasonable requirement for monad comprehensions as the two are closely
related. We give more details in Section~\ref{sec:proposals-mzip}, but many of the equivalences in 
Figure~\ref{fig:transformations} can be rewritten using the \textit{zip comprehension} syntax. 

The first two laws allow arbitrary rearrangement of arguments aggregated using the |mzip_| operation.
This is required by \textit{argument ordering} (2). The laws are expressed using two helper functions:
\begin{align*}
  a \mzip (b \mzip c) &\equiv \map \: \Varid{assoc} \: ((a \mzip b) \mzip c) \tag{associativity} \\
  a \mzip b &\equiv \map \: \Varid{swap} \: (b \mzip a) \tag{symmetry} \\
\\[-10pt]
  \textbf{where} & \: \Varid{assoc}((a,b), c) = (a,(b,c))\\
                 & \: \Varid{swap}(a,b) = (b,a)
\end{align*}
As discussed in Section~\ref{sec:theory-monoidal}, these two laws are founded in mathematical theory 
behind joinads. The |mzip_| operation is component of a \textit{symmetric monoidal functor} that requires 
both of the above laws. Another law that is also required by this formalism is \textit{naturality}, which 
is one of three laws that relate |mzip_| to other operations:

\begin{align*}
  \map \: f \: a \mzip \map \: g \: b &\equiv \map \: (f \times g) \: (a \mzip b) \tag{naturality} \\
  \Varid{return} \: a \mzip \Varid{return} \: b &\equiv \Varid{return} \: (a, b) \tag{product} \\
  a \mzip a &\equiv \map \: \Varid{dup} \: a \tag{duplication} \\
\\[-10pt]
  \textbf{where} & \: \Varid{dup} \: a = (a, a)
\end{align*}
These laws follow from the three \textit{matching} equivalences and specify the result of
applying $\mzip$ to specific monadic values:
\begin{itemize}
\item In \textit{naturality}, the arguments are created using |map|. The application of $\mzip$ is
  lifted to be performed before the mapping. The mapping then transform both elements of the 
  combined tuple.
  
\item In \textit{product}, the arguments are created using |return|. The combination of values is
  lifted to be performed before the use of |return| and becomes a tuple constructor.

\item In \textit{duplication}, the arguments are two copies of the same monadic value. The 
  duplication can be lifted inside the monad and performed on the actual values using |map|.

\end{itemize}
The next law specifies that |mzero| is the \textit{zero element} with respect to $\mzip$
(thanks to the symmetry of |mzip_|, it is both left and right zero):
\begin{align*}
  a \mzip \mzero \equiv \mzero \equiv \mzero \mzip a \tag {zero} 
\end{align*}
This law is intuitively necessary. An |mzero| value of type |m a| does not contain any value of type
|a|. Thus, given a value of type |b|, there is no way to construct a value of type |(a, b)|.

\paragraph{Applicative functors.} Given a monad, it is possible to define one instance of applicative
functor (\ident{Applicative} type class). An equivalent definition of this type class described
by McBride and Paterson \cite{applicative} defines an operation $\star$ that has exactly 
the same type as $\mzip$, but \ident{Applicative} does not require \textit{symmetry}. 

The laws are different, hence the $\mzip$ operation is an independent addition to a monad. As 
discussed in an earlier paper \cite{joinads}, for commutative monads, the $\mzip$ operation can be 
defined using |>>=| and |return|, but this is not possible in general. For some types, the $\mzip$ 
operation is a part of a distinct \ident{Applicative} instance. For example, $\star$ for a standard 
\ident{List} monad is a Cartesian product, but $\mzip$ for lists is |zip|. This operation defines 
a distinct applicative functor (over the same type) named \ident{ZipList}.

% --------------------------------------------------------------------------------------------------

\subsection{MonadOr type class}
\label{sec:laws-monador}

The \ident{MonadOr} type class defines the |morelse| operation (written as $\morelse$). As
already discussed in Section~\ref{sec:extension-typeclass}, it represents a left-biased monoid.
The monoid operation should be associative and have a unit element (|mzero| in case of joinads). 
In Haskell, it should also obey a form of naturality law:
\begin{align*}
  (u \morelse v) \morelse w &\equiv u \morelse (v \morelse w) \tag{associativity} \\
  (\map \: f \: u) \morelse (\map \: f \: v) &\equiv \map \: f \: (u \morelse v) \tag{naturality} \\
  u \morelse \mzero \equiv \: u &\equiv \mzero \morelse u \tag{unit}
\end{align*}
The \textit{unit} law is required by the \textit{alternative noninterference} (4) equivalence; 
the \textit{naturality} is needed by multiple equivalences including \textit{distributivity} (9).
Finally, the \textit{associativity} law does not directly correspond to any equivalence, but it 
specifies that the bracketing does not matter when aggregating the alternatives using $\morelse$
and makes this an unimportant implementation detail.

The left bias of the |morelse_| operation is required by \textit{clause ordering} (3).
The equivalence gives the following law:
\begin{align*}
  u \morelse \map \: f \: u \equiv u \tag{left bias}
\end{align*}
The law considers a monadic value and an image created using |map|. When choosing 
between the two, the $\morelse$ operation constructs a value that is equivalent to the left 
argument. Intuitively, the |map| operation creates a monadic value with the same structure as the 
original. The law specifies that $\morelse$ prefers values from the left argument when both 
arguments have the same structure.
The \textit{left bias} law is different than the \textit{left catch} law that is 
required about \ident{MonadOr} in the \ident{MonadPlus} reform proposal \cite{monadplusreform}. 
We return to this topic in Section~\ref{sec:proposals-morelse}, which discusses proposals for 
Haskell libraries.

\subsection{MonadZip and MonadOr relation}
Perhaps the most interesting law is required by the \textit{distributivity} (9) equivalence.
The law relates the $\morelse$ operation with $\mzip$ and fits very nicely with the rest of the 
theory: 
\begin{align*}
  a \mzip (b \morelse c) \equiv (a \mzip b) \morelse (a \mzip c) \tag{distributivity}
\end{align*}
This simple formulation does not hold when duplicating reference to $a$ also duplicates effects 
and $\morelse$ is not able to undo the effects. For |docase_|, the value $a$ is always created by 
|malias|, so we could require a weaker law (that passes |a| to |malias| first). We prefer the 
stronger version above for its simplicity. Thanks to the symmetry of $\mzip$, the law above also 
implies right distributivity.

% --------------------------------------------------------------------------------------------------

\subsection{MonadAlias type class}
This section identifies the |malias| laws. The type of the operation is |m a -> m (m a)| and we 
treat it as a way to represent aliasing of monadic computations. As discussed in 
Section~\ref{sec:theory-comonads}, operations of this type have other uses (with different set 
of laws).

The number of laws is relatively high, because |malias| needs to interact with all other 
monad and joinad operations in a particular way. The following three laws consider |mzero| and |return|
and are implied by \textit{binding equivalence} (1), \textit{matching units} (6) and \textit{argument
noninterference} (5), respectively:
\begin{align*}
\malias \: a \bind \Varid{id} &\equiv a \tag{join identity} \\
\malias \: (\Varid{return} \: a) &\equiv \Varid{return} \: (\Varid{return} \: a) \tag{unit identity} \\
\malias \: \mzero &\equiv \Varid{return} \: \mzero \tag{zero identity}
\end{align*}
In the first law, applying |malias| to a monadic value of type |m a| yields a value of type 
|m (m a)|. The law specifies that immediate binding and returning has the same meaning as the original
computation\footnote{The law can be reformulated using monadic join as $\Varid{join} (\malias \: a) \equiv a$}.
The next laws specify that aliasing of pure computation or failed computation does not have any effect. 

The next four laws consider |malias| given as an argument to~|>>=| together with a function constructed
in some special way. 
\begin{align*}
(\malias \: m \bind f) \mzip n &\equiv \malias \: m \bind (\mzip \: n) \circ f \\ % \tag{lifting}\\
\malias \: (\malias \: m \bind f) \bind g &\equiv \malias \: m \bind (g \circ f) \\ %  \tag{nesting} \\
\map \: (\map \: f) \: (\malias \: m) &\equiv \malias \: (\map \: f \: m) \\ % \tag{naturality} \\
\map \: \Varid{swap} \: (\malias \: m \star \malias \: n) &\equiv \malias \: n \star \malias \: m 
\end{align*}
\begin{align*}
  \textbf{where} \: &m \star n = m \bind \lambda x \rightarrow n \bind \lambda y \rightarrow \Varid{return} \: (x, y)
\end{align*}
The first two laws are required by \textit{distributivity} (9) to 
deal with nested aliasing and zipping of an aliased computation. The third law is implied by
\textit{matching images} (7) to lift the |map| operation over aliasing and the last law is required
for \textit{binding equivalence} (1) to reorder independent aliasing.

% ==================================================================================================

\section{Theory of joinads}
\label{sec:theory}

This section looks at categorical foundations of joinads and consider an algebraic structure
formed by |mzip_| and |morelse_|.

% --------------------------------------------------------------------------------------------------

\subsection{Monoidal functors}
\label{sec:theory-monoidal}

The discussion about \ident{MonadZip} and \ident{Applicative} from Section \ref{sec:laws-monadzip}
can be recast in terms of category theory, because an \ident{Applicative} instance corresponds to a 
monoidal functor. Given a monad, we can construct a monoidal functor. The 
\ident{MonadZip} type class with the laws given above corresponds to a \textit{symmetric monoidal 
functor} and $\mzip$ is the natural transformation defined by it. This is another justification for 
the \textit{naturality}, \textit{associativity} and \textit{symmetry} laws. 

Joinads combine this symmetric monoidal functor with a monad and thus also a monoidal functor 
specified by the monad. The underlying functor is the same, but the natural transformation and units 
differ. The unit of the $\mzip$ operation is not needed by joinads, so we do not require users to 
define it. In particular, this means that |return| does not behave as unit with respect to $\mzip$. 
For example, a unit for \ident{List} is a singleton list, but unit for \ident{ZipList} is an infinite
list. Zipping a list with an infinite list and then projecting out first elements of a tuple
gives the original list, but the same is not true for zipping with a singleton list.

% --------------------------------------------------------------------------------------------------

\subsection{Computational comonads}
\label{sec:theory-comonads}

The type of the |malias| operation is the same as the type signature of |cojoin| operation of a 
comonad. Although less frequent than monads, comonads are also a useful notion of computations in 
functional programming \cite{comomads-ypnos, comonads-dataflow}, so it is worth considering how they 
relate to joinads. Comonads can be defined in multiple (equivalent) ways. The definition that uses |
cojoin| extends \ident{Functor} with two operations and is shown in Figure~\ref{fig:comonad-class}. 
The |coreturn| operation is dual to |return| of a monad and |cojoin| is dual to monadic |join| which 
has the type |m (m a) -> m a|.

The |cojoin| operation of a comonad could be used as the basis of |malias|, although joinads do not 
need the rest of the comonadic structure (the |coreturn| operation).
We would only consider comonad laws that do not involve |coreturn|:
\begin{align*}
\map \: (\map \: f) \: (\Varid{cojoin} \: a) &\equiv \Varid{cojoin} \: (\map \: f \: a)\\
\map \: \Varid{cojoin} \: (\Varid{cojoin} \: a) &\equiv \Varid{cojoin} \: (\Varid{cojoin} \: a)
\end{align*}
The first law is, indeed, one of the laws that we require to hold about the |malias| operation.
The second law is not required to prove the equivalences from Figure~\ref{fig:transformations},
so we did not include it. However, it could be added and it should intuitively hold for |malias|.

Furthermore, \emph{computational comonads} introduced by Brookes and Geva \cite{comp-comonads} 
are even more closely related to joinads. A computational comonad is a comonad $(T, \epsilon, \delta)$
with an additional \emph{natural transformation} $\gamma : I_C \rightarrow T$. In terms of Haskell, this
is a function of type |a -> m a| and it coincides with the |return| operation of a joinad. 
Computational comonad has to satisfy the usual laws of a comonad together with three additional
operations that relate $\gamma$ with |cojoin| and |coreturn|. We write |return| 
for $\gamma$:
\begin{align*}
\map \: f \: (\Varid{return} \: a) &\equiv \Varid{return} \: (f \: a) \\
\mcojoin \: (\Varid{return} \: a) &\equiv \Varid{return} \: (\Varid{return} \: a)\\
\Varid{coreturn} \: (\Varid{return} \: a) &\equiv a 
\end{align*}
The first law is a naturality law of the |return| operation that can be proved from the standard 
monad laws and therefore it holds for joinads. The second law corresponds to the \emph{unit identity}
law that we also require about joinads (it is required by the \textit{matching units} (6) 
transformation). Finally, the third law of computational comonads involves the |coreturn| operation
that is not present in joinads, so it is not directly relevant. We find this close correspondence
intriguing and intend to explore it in a future work.

\begin{figure}
\begin{code}
class Functor m => Comonad m where
  cojoin :: m a -> m (m a)
  coreturn :: m a -> a
\end{code}
\caption{Definition of \ident{Comonad} type class. }
\label{fig:comonad-class}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsection{Joinad algebra} 
\label{sec:theory-algebra}

The laws about |mzip_| and |morelse_| discussed in the previous section suggest that 
joinads can be modelled as an algebraic structure. Assume that $J$ is a set containing all monadic 
values of some type |m a| for the same joiand |m|. The |mzero| value is a special element $0 \in J$.
\begin{itemize}
\item The |mplus_| operation is associative and has $0$ as the identity element. This means that the
  structure $(J, \mplus, 0)$ is a monoid.

\item The |mzip_| operation is commutative and associative, which means that $(J, \mzip)$ is a 
  commutative semigroup. Additionally, the semigroup has $0$ as the zero element.
  
\item Finally, the |mzip_| operation distributes over the |mplus_| operation.
\end{itemize}
These axioms characterize an algebraic structure called \textit{near-semiring} with commutative
$\mzip$ operation. This specification captures the essence of joinads---the only 
thing that is left out is the left bias of the $\morelse$ operation. As discussed in 
Section~\ref{sec:related-monadplus} this general case may be also useful, but we require left bias
so that |docase_| has semantics inspired by the Haskell's |case| construct.

% ==================================================================================================

\section{Feature interactions and library proposals}
\label{sec:proposals}

Joinads combine type classes that are already known to the Haskell 
community. This section considers adjustments that could be made to \ident{MonadZip} and 
\ident{MonadOr} in order to accommodate joinads.

% --------------------------------------------------------------------------------------------------

\subsection{Monad comprehension laws} 
\label{sec:proposals-mzip}

There is an ongoing discussion about the laws that should be required for parallel monad 
comprehensions \cite{bringbackmc, comprefun}. The original documentation specified the following two laws
about \ident{MonadZip}:
\begin{align*}
  \map \: f \: a \mzip \map \: g \: b &\equiv \map \: (f \times g) \: (a \mzip b) \tag{naturality} \\
  \map \: \Varid{fst} \: (a \mzip b) &\equiv a \tag{information preservation} 
\end{align*}

\paragraph{Monoidal laws.}
The \textit{naturality} law was also proposed for joinads (Section \ref{sec:laws-monadzip}). It
arises from the syntactic equivalences, but also from the fact that the |mzip| operation is defined by a 
monoidal functor. We propose the following two additions:

\begin{itemize}
\item The \textit{associativity} law also arises from a monoidal functor,
  hence the two should be both required.
  
\item Symmetry is an essential aspect of |mzip| and we argue that 
  the \textit{symmetry} law should be also included in \ident{MonadZip}.

\end{itemize}
The symmetry of |mzip| holds for lists as well as for the \ident{MonadZip} instances presented in 
this paper. In terms of parallel monad comprehensions, the law guarantees the following 
equivalence:
\begin{code}
[(a, b) | a <- m^sub(1) | b <- m^sub(2)] == [(a, b) | b <- m^sub(2) | a <- m^sub(1)]
\end{code}
The symmetry means that the |mzip| operation cannot be automatically implemented in 
terms of |>>=| and |return|. This specifies that the additional syntax
should also have an additional meaning. It is still possible to get |mzip| for free, 
but only for \textit{commutative monads}, which is discussed in earlier work on 
joinads \cite{joinads}.

\paragraph{Information preservation.}
The second law specifies that we can recover the original arguments of a value created using 
|mzip_|. This law is problematic. It allows applying |mzip| to inputs with different structure 
(i.e. length of the list), but recovering the original values is only possible if 
the structure of arguments is the same. For example, |zip| for lists restricts the length to the
length of the shorter lists, so the original law does not hold for lists of different length.

Using \textit{naturality} and the \textit{duplication} law, we can derive the
following law that looks similar and clarifies the requirement about the structure of values:
\begin{align*}
  \map \: \Varid{fst} \: (a \mzip \: \map f a) \equiv a \equiv \map \: \Varid{snd} \: (\map \: g \: a \: \mzip \: a)
\end{align*}
Instead of zipping two arbitrary monadic values, the law zips a value with an image created using 
|map|. Thanks to the properties of |map|, the law only concerns zipping of monadic values with the 
same structure. Hence, we make the following proposal:

\begin{itemize}
\item The \textit{information preservation} law does not hold for many standard implementations of 
  |mzip|, so we propose replacing it with the weaker form presented above.

% Maybe (not that important)
%
% \item In terms of monad comprehensions, the \textit{product} law of joinads states that 
%   |[(ma, mb)|| ma <- return a || mb <- return b]| should be equivalent to |return (a, b)|. We find 
%   this a useful requirement for monad comprehensions.
\end{itemize}
The \textit{product} and \textit{zero} laws can be also translated in terms of parallel
monad comprehensions, but we do not find them as essential.

% --------------------------------------------------------------------------------------------------

\subsection{Left-biased additive monads}
\label{sec:proposals-morelse}

Monads that are also monoids and provide an |mzero| element and an associative |mplus_|
operation are captured by the \ident{MonadPlus} type class from the standard Haskell library. 
However, there is some confusion about the additional laws that should hold. The \ident{MonadPlus} 
reform proposal \cite{monadplusreform} provides a solution by splitting the type class into \ident{MonadPlus} 
obeying the \textit{left distribution} law and \ident{MonadOr} obeying the \textit{left catch} law. The
\textit{left bias} law that we require for joinads (Section \ref{sec:laws-monador}) adds a third
alternative:
\begin{align*}
  u \mplus v \bind f &\equiv (u \bind f) \mplus (v \bind f) \tag{left distribution}\\
  (\Varid{return} \: a) \mplus u &\equiv \Varid{return} \: a \tag{left catch} \\
  u \morelse \map \: f \: u &\equiv u \tag{left bias}
\end{align*}
It is not difficult to find counter-examples showing that none of the three laws implies some other.
Both \textit{left bias} and \textit{left catch} represent some form of left bias, but in a 
different way. 

\begin{itemize}
\item The \textit{left bias} law uses an arbitrary value as the left
  and a special value (constructed using |map|) as the right argument. 

\item The \textit{left catch} law uses an arbitrary value as the right 
  and a special value (constructed using |unit|) as the left argument. 
\end{itemize}
Despite the difference, the main purpose of the two laws is the same. They both specify that the 
operation is left biased. Which law should hold about \ident{MonadOr}? One option is to consider 
the upper or the lower bound of the two laws:

\begin{align*}
  (\Varid{return} \: a) \mplus (\Varid{return} \: b) &\equiv \Varid{return} \: a \tag{lower bound} \\
  u \morelse u \bind f &\equiv u \tag{upper bound}
\end{align*}
The \textit{upper bound} implies by both left bias and left catch, while the \textit{lower
bound} is implied by any of the two. It is not clear to us whether any monad can provide a 
non-trivial implementation of |mplus_| satisfying the \textit{upper bound} law. 
The \textit{lower bound} law is more appropriate, although it is not sufficient to prove that the 
\textit{clause ordering} equation from Section \ref{sec:reasoning} holds.

We argue that \textit{left bias} better captures the purpose. The most prominent monad that satisfies
\ident{MonadOr} laws is the \ident{Maybe} monad, which obeys both of the laws. We can also give a 
useful implementation of |morelse| that obeys the left bias law for the \ident{List} monad. The 
two declarations are shown in Figure~\ref{fig:monador-instances}. An alternative would be to 
separate the type from the laws that are required in the language, but this is a separate research
topic.

\begin{figure}
\begin{code}
instance MonadOr [] where
  morelse (x:xs) (y:ys) = x:morelse xs ys
  morelse [] ys = ys
  morelse xs [] = xs

instance MonadOr Maybe where
  morelse (Just a) _ = Just a
  morelse Nothing b = b
\end{code}
\caption{Instance of \ident{MonadOr} that obey left bias law}
\label{fig:monador-instances}
\end{figure}

% ==================================================================================================

\section{Related and future work}
\label{sec:related}

We presented an earlier version of joinads in \fsharp \cite{joinads} using different examples. 
An article for The Monad.Reader \cite{parcomprefun} provides more details on the relation between 
joinads and \textit{monad comprehensions}.

The rest of this section presents some of the important related work on pattern matching, concurrent
programming and abstract computation types as well as preliminary ideas for future work.

% --------------------------------------------------------------------------------------------------

\subsection{Backtracking and committing patterns}
\label{sec:related-monadplus}

Existing work on pattern matching has focused on enabling pattern matching on abstract values 
using views \cite{views-haskell}. A similar concept also appeared in \fsharp and Scala 
\cite{scala-patternmatching, activepatterns}. Making patterns first-class made it possible to encode 
the Join calculus using Scala \cite{scala-encodingjoins}, although the encoding is somewhat opaque.

Some authors \cite{firstlcasspats, activepatterns} have suggested generalizing the result of 
pattern matching from \ident{Maybe} (representing a failure or a success) to any additive monad 
using the \ident{MonadPlus} type class. The concrete examples included encoding of backtracking 
using the \ident{List} monad and composing transactions using \ident{STM}.

The next example demonstrates the difference between joinads as described here and the \ident{MonadPlus}
interpretation. Assuming standard parser combinators (|char|, |many|, and |item|), 
we can write:

\begin{code}
body = mcase_ (char '(', many item) of 
  (_, ?)    -> do  str <- body
                   _ <- char ')'
                   return str
  (?, str)  -> return str
\end{code}
The |mcase_| construct (similar to our |docase_|) represents a monadic pattern matching using 
\ident{MonadPlus}. In the syntax designed for active patterns \cite{activepatterns}, monadic 
values were produced by \textit{active patterns} that return monadic values. For parsers, the 
type of active patterns would be |a -> Parser b|. This leads to a different syntax, but it is 
possible to translate between the two options.

The translation based on \ident{MonadPlus} follows similar pattern as the translation of joinads,
but differs in three ways:

\begin{code}
(char '(' >>= \_ -> body >>= \str ->
    char ')' >>= \_ -> return str) mplus_
(many item >>= \str -> return str)
\end{code}
The first difference (apparent from this example) is that the proposed encoding using \ident{MonadPlus}
does not add additional wrapping around the body of the alternatives to support committing to an 
alternative. The second difference is that \ident{MonadPlus} usually requires the \textit{left
distributivity} law instead of the \textit{left bias} law required by \ident{MonadOr}. Finally, 
multiple binding patterns are translated using nested |>>=| instead of a special |mzip| operation.

\begin{itemize}
\item When using \ident{MonadOr}, the |mplus_| operation attempts to parse the input using the
  first alternative. Other alternatives are considered only if the first one fails. The above parser 
  would deterministically parse ``((1))'' as ``1''. The laws of \ident{MonadPlus} make the resulting 
  parser non-deterministic, so it would generate three options: ``1'', ``(1)'' or ``((1))''.

\item Without the additional wrapping, the parser needs to implement backtracking. If the
  input is ``(1'', the first alternative is selected, continues consuming input, but then fails.
  The parser needs to backtrack to the point when |mplus_| was used and try the second alternative. 
  When using wrapping, the parser will commit to the first alternative, which is an approach used
  by modern libraries such as Parsec \cite{parsec}.

\item Combining multiple inputs using the |mzip| operation means that the arguments of |docase_|
  can be reordered even for non-commutative monads. A separate |mzip| operation may also enable 
  additional optimizations, for example, in the \ident{STM} monad.

\end{itemize}
The example above shows that all of the options may have a feasible meaning for some monads. We find 
the joinad-based semantics of |docase_| that supports commit points more appropriate for monads from 
functional programming. The variant using \ident{MonadPlus} often implies backtracking and thus may 
be more suitable for logic programming languages such as Prolog. 

% --------------------------------------------------------------------------------------------------

\subsection{Commit points in remote procedure calls}
The discussion about commit points in Section \ref{sec:intro-commit-poorman} was inspired by 
Concurrent ML (CML) \cite{concurrentml}. CML is a concurrent programming language built on top
of Standard ML. It supports first-class synchronization values called \textit{events} that can 
be used to encode many common concurrent programming patterns. Joinads, on the other hand, capture 
a single pattern that we find extremely important. 

We demonstrate the relation between joinads and CML, by showing two implementations of a 
remote procedure call (RPC). Assume we have a monad for blocking communication
and monadic computations |send|, |recv| that represent sending request and receiving a response. As an 
alternative to performing the RPC call, the client can choose to perform another operation |alt|.

One way to implement the RPC call is to initiate a call, but allow abandoning the RPC communication
at any time until it completes. This means that receiving a response from the server is used
as a commit point for the RPC call:

\begin{code}
docase_ (send, recv, alt) of
  ((), res, ?)  -> handleRpc res
  (?, ?, a)     -> handleAlt a
\end{code}
We can assume that the event |recv| becomes enabled after |send|, so the first alternative becomes
enabled after the server replies. The second alternative will be selected if the |alt| event is
enabled earlier. This may, or may not, happen before the server accepts the request and 
enables the |send| event.

The second way to implement RPC is to allow abandoning the communication only before the server 
accepts the request. After that, the client waits for |recv| event and cannot choose |alt| instead:

\begin{code}
docase_ (send, alt) of
  ((), ?)  ->  do res <- recv
               handleRpc res
  (?, a)   ->  handleAlt a
\end{code}
In this version of code, the |docase_| construct only chooses between |send| and |alt|. Once the
first alternative is selected, it has to wait for the server response using |recv|.

This section demonstrates that joinads can capture the two essential patterns for writing RPC
communication as introduced in Concurrent ML. This example critically relies on the support for
commit points introduced in Section \ref{sec:intro-commit-poorman}. When using the simple encoding
discussed in Section \ref{sec:related-monadplus}, the two expressions would translate to the 
same meaning.

% --------------------------------------------------------------------------------------------------

\subsection{Joinads and other computation types}
Joinads extend monads to support the |docase_| construct, but functional languages use several other
notions of computation. In the future, it may be interesting to consider how other computations
relate to generalized pattern matching. Comonads (a categorical dual of monads) \cite{comonads-codata} 
have been used for encoding data-flow programs \cite{comonads-dataflow}, but also for stencil 
computations using special \textit{grid patterns} \cite{comomads-ypnos}. Arrows 
\cite{generalisingmonads, causalarr} are used mainly in functional reactive programming research 
\cite{arrows-frp} and can be written using the arrow notation \cite{arrows-notation} (in a similar 
way to how monads use the |do| notation).

Another notion of computation is called \textit{applicative functors} \cite{applicative} or 
\textit{idioms}, which are weaker than monads and can thus capture larger number of computations. 
Haskell libraries also include an \ident{Alternative} type class that extends applicative functors 
with a |diamond_| operator similar to |mplus_| from \ident{MonadPlus} or \ident{MonadOr}. The 
declaration is shown in Figure \ref{fig:alternative-typeclass}. The figure shows \ident{Monoidal} type
class, which is equivalent to a more common \ident{Applicative} class (as discussed by McBride and 
Patterson \cite{applicative} in Section 7), because this variation better reveals similarity with
joinad operations.

\begin{figure}
\begin{code}
class Functor f => Monoidal f where
  unit :: f ()
  (star_) :: f a -> f b -> f (a, b)

class Monoidal f => Alternative f where
  empty :: f a
  (diamond_) :: f a -> f a -> f a
\end{code}
\caption{\ident{Alternative} type class}
\label{fig:alternative-typeclass}
\end{figure}

Interestingly, the operations of \ident{Alternative} have the same types as the two most essential 
operations of joinads. The |star_| operation has the same type as our |mzip|, representing parallel 
composition, and |diamond_| has the type of |morelse|, representing a choice. It is well known that
applicative functors are more general than monads and \ident{Alternative} may generalize joinads
in a similar way.

% --------------------------------------------------------------------------------------------------

\subsection{Applications}
We demonstrated that |docase_| notation can be used for working with many common 
monads. When using monadic parser combinators \cite{monadparsing} the |morelse| operation
represents left-biased choice as supported in \cite{parsec}. As discussed in our earlier article,
our implementation of parallel composition (the |mzip| operation) corresponds to the intersection
of context-free grammars \cite{parcomprefun}. We are not aware of any parser combinator library that
provides this operation, but it seems to be very useful for validation of inputs (eliminating inputs
that do not match any of the given parsers).

The reactive programming examples used in this paper were based on imperative streams developed by 
Scholz \cite{imperative-streams}. Imperative streams are essentially monads for synchronous 
reactive programming. A Push-Pull Functional Reactive Programming framework developed by Elliott 
\cite{push-pull-frp} includes a monad instance for events, so it could likely benefit from the
|docase_| syntax too.

The parallel programming model that we presented can be added to various existing Haskell frameworks.
Our earlier article \cite{parcomprefun} used strategies \cite{strategies-new}. In this paper,
we embedded the examples in the \ident{Par} monad \cite{parmonad} with several extensions to
allow speculative computations \cite{parmonad-cancellation}. The programming model is very
similar to the |pcase_| construct provided by Manticore \cite{manticore}.

% ==================================================================================================

\section{Conclusions}
This paper presented a characterization of monadic computations that provide three additional 
operations: \textit{aliasing}, \textit{parallel composition} and \textit{choice}. 
These operations are not new to Haskell. They are captured by type classes \ident{Extend}, 
\ident{MonadZip} and \ident{MonadOr}. We combined them and designed a |docase_| notation that makes 
it easy to compose computations using these operations.

The |docase_| notation is inspired by our previous work on joinads in \fsharp. However, this paper
uses a simpler set of operations that are amenable to formal reasoning. We started with a set of 
semantics-preserving transformations that are intuitively expected to hold about the |docase_| construct. We 
derived a set of laws about joinad operations and used the Coq theorem prover to show that these 
suffice to perform the intuitive transformations. We also noted that joinads form an algebraic 
structure known as \textit{near-semiring}.

Finally, we also made several concrete library proposals based on our work. In particular, we support
the proposal to distinguish between unbiased \ident{MonadPlus} and left-biased \ident{MonadOr} and we
propose a refined set of laws that should be required by \ident{MonadZip}. We demonstrated the
usefulness of our extension using a wide range of monads including reactive and parallel programming
as well as input validation using monadic parsers. 

% ==================================================================================================

\acks
We are grateful to Philip Wadler for encouraging feedback about earlier versions of this work and to 
Dominic Orchard for many useful discussions about this paper and Haskell in general. Simon Peyton 
Jones, Gregory Neverov, Dmitry Lomov and James Margetson all provided useful comments about early 
work on joinads. We also thank to anonymous referees for useful comments.


% ==================================================================================================

\begin{thebibliography}{37}
\raggedright
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[bri()]{bringbackmc}
Haskell Trac.
\newblock Bring back monad comprehensions, retrieved 2011.
\url{http://hackage.haskell.org/trac/ghc/ticket/4370}.

\bibitem[mon()]{monadplusdoc}
Haskell Documentation.
\newblock Control.Monad, retrieved 2011

\bibitem[Brookes(1991)]{comp-comonads}
S.~Brookes, S.~Geva.
\newblock Computational comonads and intensional semantics.
\newblock Technical Report CMU-CS-91-190, Carnegie Mellon University, 1991.

\bibitem[Brown(2008)]{chp-monad}
N.~C.~C. Brown.
\newblock {C}ommunicating {H}askell {P}rocesses: {C}omposable {E}xplicit
  {C}oncurrency using {M}onads.
\newblock In \emph{{C}ommunicating {P}rocess {A}rchitectures 2008}, pages
  67--83, 2008.

\bibitem[Claessen(1999)]{poorman}
K.~Claessen.
\newblock A Poor Man's Concurrency Monad.
\newblock \emph{Journal of Functional Programming}, 9:\penalty0 313--323, May
  1999.
\newblock ISSN 0956-7968.

\bibitem[Elliott(2009)]{push-pull-frp}
C.~Elliott.
\newblock Push-Pull Functional Reactive Programming.
\newblock In \emph{Haskell Symposium}, 2009.

\bibitem[Emir et~al.(2007)Emir, Odersky, and Williams]{scala-patternmatching}
B.~Emir, M.~Odersky, and J.~Williams.
\newblock Matching Objects with Patterns.
\newblock In \emph{ECOOP 2007}, 2007.

\bibitem[Fluet et~al.(2010)Fluet, Rainey, Reppy, and Shaw]{manticore}
M.~Fluet, M.~Rainey, J.~Reppy, and A.~Shaw.
\newblock Implicitly threaded parallelism in {M}anticore.
\newblock \emph{Journal of Functional Programming}, 20\penalty0 (Special Issue
  5-6):\penalty0 537--576, 2010.

\bibitem[Schweinsberg(2010)]{comprefun}
G.~Giorgidze, T.~Grust, N.~Schweinsberg, and J.~Weijers
\newblock Bringing Back Monad Comprehensions.
\newblock To appear in \emph{Haskell'11}, 2011

\bibitem[Haller and Van~Cutsem(2008)]{scala-encodingjoins}
P.~Haller and T.~Van~Cutsem.
\newblock Implementing {J}oins using {E}xtensible {P}attern {M}atching.
\newblock In \emph{Proceedings of the 10th {I}nternational {C}onference on
  {C}oordination {M}odels and {L}anguages}, 2008.

\bibitem[HaskellWiki(2011)]{monadplusreform}
HaskellWiki.
\newblock MonadPlus reform proposal, retrieved 2011.
\newblock \url{http://tinyurl.com/monadplus-reform-proposal}.

\bibitem[Hudak et~al.(2003)Hudak, Courtney, Nilsson, and Peterson]{arrows-frp}
P.~Hudak, A.~Courtney, H.~Nilsson, and J.~Peterson.
\newblock Arrows, Robots, and Functional Reactive Programming.
\newblock In \emph{Advanced Functional Programming}, volume 2638 of
  \emph{LNCS}, pages 1949--1949. 2003.

\bibitem[Hughes(1998)]{generalisingmonads}
J.~Hughes.
\newblock Generalising Monads to Arrows.
\newblock \emph{Science of Computer Programming}, 37:\penalty0 67--111, 1998.

\bibitem[Hutton and Meijer(1998)]{monadparsing}
G.~Hutton and E.~Meijer.
\newblock {Monadic Parsing in Haskell}.
\newblock \emph{Journal of Functional Programming}, 8\penalty0 (4):\penalty0
  437--444, July 1998.

\bibitem[Simon~Marlow(2011)]{parmonad}
S.~P.~Jones, S.~Marlow, and R.~Newton.
\newblock A Monad for Deterministic Parallelism, 2011.
\newblock \url{http://tinyurl.com/monad-par}.

\bibitem[Jones and Wadler(2007)]{groupordercompre}
S.~P. Jones and P.~Wadler.
\newblock Comprehensive Comprehensions.
\newblock In \emph{Haskell'07}, pages 61--72, 2007.

\bibitem[Kieburtz()]{comonads-codata}
R.~B. Kieburtz.
\newblock Codata and Comonads in Haskell.
\newblock Unpublished manuscript, 1999.

\bibitem[Kmett(2011)]{comonadpkg}
E.~A. Kmett.
\newblock The comonad package, retrieved 2011.
\newblock \url{http://hackage.haskell.org/package/comonad}.

\bibitem[Leijen and Meijer(2001)]{parsec}
D.~Leijen and E.~Meijer.
\newblock Parsec: Direct Style Monadic Parser Combinators for the Real World.
\newblock Technical Report UU-CS-2001-27, Department of Computer Science,
  Universiteit Utrecht, 2001.

\bibitem[Liu et~al.(2009)Liu, Cheng, and Hudak]{causalarr}
H.~Liu, E.~Cheng, and P.~Hudak.
\newblock Causal Commutative Arrows and Their Optimization.
\newblock In \emph{ICFP'09}, pages 35--46, 2009.

\bibitem[Marlow et~al.(2010)Marlow, Maier, Loidl, Aswad, and
  Trinder]{strategies-new}
S.~Marlow, P.~Maier, H.-W. Loidl, M.~K. Aswad, and P.~Trinder.
\newblock Seq no more: Better Strategies for Parallel Haskell.
\newblock In \emph{Haskell'10}.

\bibitem[McBride and Paterson(2007)]{applicative}
C.~McBride and R.~Paterson.
\newblock Applicative Programming with Effects.
\newblock \emph{Journal of Functional Programming}, 18:\penalty0 1--13, 2007.

\bibitem[Orchard et~al.(2010)Orchard, Bolingbroke, and Mycroft]{comomads-ypnos}
D.~A. Orchard, M.~Bolingbroke, and A.~Mycroft.
\newblock Ypnos: Declarative, Parallel Structured Grid Programming.
\newblock DAMP '10, 2010.

\bibitem[Paterson(2001)]{arrows-notation}
R.~Paterson.
\newblock A New Notation for Arrows.
\newblock In Proceedings of \emph{ICFP'01}, pages
  229--240. ACM Press, Sept. 2001.

\bibitem[Petricek(2011{\natexlab{a}})]{parcomprefun}
T.~Petricek.
\newblock Fun with parallel monad comprehensions, 2011{\natexlab{a}}.
\newblock The Monad.Reader, Issue 18.

\bibitem[Petricek(2011{\natexlab{b}})]{parmonad-cancellation}
T.~Petricek.
\newblock Explicit speculative parallelism for Haskell's Par monad,
\url{http://tomasp.net/blog/speculative-par-monad.aspx}, retrieved 2011.

\bibitem[Petricek and Syme(2011)]{joinads}
T.~Petricek and D.~Syme.
\newblock Joinads: A retargetable control-flow construct for reactive, parallel
  and concurrent programming.
\newblock In \emph{PADL'11}, pages 205--219, 2011.

\bibitem[Reppy(2007)]{concurrentml}
J.~H. Reppy.
\newblock \emph{Concurrent Programming in ML}.
\newblock Cambridge University Press, 2007.
\newblock ISBN 978-0-521-71472-3.

\bibitem[Scholz(1998)]{imperative-streams}
E.~Scholz.
\newblock Imperative Streams---A Monadic Combinator Library for Synchronous Programming.
\newblock In \empty{ICFP'98}, 1998.

\bibitem[Swierstra(2008)]{parsingtutorial}
S.~D. Swierstra.
\newblock Combinator Parsing: A Short Tutorial.
\newblock Technical report, Utrecht University, 2008.

\bibitem[Syme et~al.(2007)Syme, Neverov, and Margetson]{activepatterns}
D.~Syme, G.~Neverov, and J.~Margetson.
\newblock Extensible Pattern Matching via a Lightweight Language Extension.
\newblock ICFP, 2007.

\bibitem[Trinder et~al.(1998)Trinder, Hammond, Loidl, and {Peyton
  Jones}]{strategies-old}
P.~W. Trinder, K.~Hammond, H.-W. Loidl, and S.~L. {Peyton Jones}.
\newblock Algorithm + {S}trategy = {P}arallelism.
\newblock \emph{Journal of Functional Programming}, 8\penalty0 (1):\penalty0
  23--60, Jan. 1998.

\bibitem[Tullsen(2000)]{firstlcasspats}
M.~Tullsen.
\newblock First-Class Patterns.
\newblock In \emph{PADL 2000}, 2000.

\bibitem[Uustalu and Vene(2005)]{comonads-dataflow}
T.~Uustalu and V.~Vene.
\newblock The essence of dataflow programming.
\newblock In \emph{APLAS}, pages 2--18, 2005.

\bibitem[Wadler(1987)]{views-haskell}
P.~Wadler.
\newblock Views: a way for pattern matching to cohabit with data abstraction.
\newblock POPL, 1987.

\bibitem[Wadler(1990)]{comprehendingmonads}
P.~Wadler.
\newblock Comprehending Monads.
\newblock In \emph{Proceedings of the 1990 ACM conference on LISP and
  functional programming}, pages 61--78, 1990

\end{thebibliography}

% ==================================================================================================

\appendix

\section{Explicit shortcircuiting}
\label{sec:appendix-shortcircuit}
The motivating example in Section~\ref{sec:motivation} used |docase_| and the \ident{Par} monad to 
implement a |all| function for trees. The function takes a predicate and tests whether it holds 
for all values stored the tree. 

The following code implements the functionality |Par| monad with an extension that allows cancellation 
of tasks \cite{parmonad-cancellation}. This code does not represent desugared version of the |docase_| 
notation. Instead, it represents a typical solution that developers may write when using the library 
directly:

\begin{code}
all :: (a -> Bool) -> Tree a -> Par Bool

all p tree = do
    tok <- newCancelToken
    r <- all' tok tree
    cancel tok 
    return r
  where 
    all' tok (Leaf v) = return (p v)
    all' tok (Node left right) = do
      leftRes <- new
      rightRes <- new
      finalRes <- newBlocking
      forkWith tok (all' tok left >>= 
        completed leftRes rightRes finalRes)
      forkWith tok (all' tok right >>= 
        completed rightRes leftRes finalRes)
      get finalRes
    
    completed varA varB fin resA = do
      put varA resA
      if not resA then put fin False
      else get varB >>= put fin . (&& resA)
\end{code}
The main function creates a new cancellation token and then calls a helper that does the 
processing. The cancellation token is used to stop all pending computations when 
the overall result is known. 

Inside |all'|, the variables |leftRes| and |rightRes| are used to store the 
result of their corresponding computations. The last variable is created differently: when
the variable is full and a computation attempts to write into it, it will block instead of
failing. The |all'| function then spawns two tasks to process sub-trees and waits for 
the final result.

The two computations both make a recursive call and then pass the result to |completed|. If the 
result is |False|, the function sets the final result. Otherwise, it waits until the other 
computation completes and then calculates the final result.

% \section{Joinads and comonads}
% \label{sec:appendix-comonad}
% In this appendix, we briefly discuss theoretical foundations of computations that are both joinads
% and comonads. In particular, we consider what is needed for |malias| and |cojoin| to overlap.
% These may arise from a pair of adjoint functors. Given two adjoint functors 
% $F \dashv U$ with unit $\eta$ and counit $\epsilon$ where $F : \mathcal{C} \rightarrow \mathcal{D}$ 
% and $U : \mathcal{D} \rightarrow \mathcal{C}$, it is possible to define a monad $(T, \eta, \mu)$
% by taking $T = U \circ F$ and $\mu = U \eta F$. Interestingly, we can also define a comonad 
% $(S, \epsilon, \delta)$ by taking $S = F \circ U$ and $\delta = F \mu U$.

% One notion of computation that is both monadic and comonadic should have just a single functor,
% which means that we would require that $T \equiv S$. This implies that the functors $F$ and $U$ must 
% have the same domain and codomain. In particular, the two adjoint functors must be both definable
% in Haskell. Finally, the \textit{join identity} law adds a requirement specifying that 
% $\mu \circ \delta = U \eta F^2 \mu U\equiv \textit{id}$. 



\end{document}








